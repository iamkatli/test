{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lxJn069QLn8O"
   },
   "source": [
    "# SIT744 Assignment 4 (T2 2025)\n",
    "\n",
    "Due: Week 11 Friday 8:00 pm (AEST)\n",
    "Weight: 20% of final grade\n",
    "\n",
    "This is an individual assignment. It contributes 20% to your final mark. Read the assignment instructions carefully.\n",
    "\n",
    "## What to submit\n",
    "By the due date, you are required to submit the following files to the corresponding Assignment (Dropbox) in CloudDeakin:\n",
    "\n",
    "- **[YourID]_[UnitCode]_assignment4_solution.ipynb**: This is your Python notebook solution source file.\n",
    "- **[YourID]_[UnitCode]_assignment4_output.pdf**: This is the output of your Python notebook solution exported in PDF format. (You may use [nbconvert](https://github.com/jupyter/nbconvert).)\n",
    "- Extra files required to complete your assignment, if any (e.g., source data used in your training).\n",
    "\n",
    "For example, if your student ID is: 123456, and you are a SIT744 student, you will then need to submit the following files:\n",
    "\n",
    "- 123456_SIT744_assignment4_solution.ipynb\n",
    "- 123456_SIT744_assignment4_output.pdf\n",
    "\n",
    "Please keep your answers short and to the point. Clean up your code outputs to reduce unnecessary information (e.g., excessively long training logs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AqJfF37paJKc"
   },
   "source": [
    "## Overview\n",
    "In this assignment you will take a lightweight, decoder-only language model and explore how effectively it can generate text in a specialised domain or authorial style. You will establish a baseline, adapt the model through both standard and parameter-efficient fine-tuning, and critically analyse the trade-offs in accuracy, efficiency, and generative quality. By the end, you should have concrete evidence (both quantitative and qualitative ) of how different adaptation strategies affect model behaviour.\n",
    "\n",
    "In this assignment, you will work with a small corpus of text that you select yourself, representing a distinctive writing style or domain, such as:\n",
    "\n",
    "Classic literature (e.g., Jane Austen, Charles Dickens)\n",
    "\n",
    "Scientific abstracts (e.g., computer science, biomedical research)\n",
    "\n",
    "Your tasks are split into three progressive sets:\n",
    "\n",
    "1. **P-Level (60%)** – establish a strong baseline by loading a pretrained model (without fine-tuing), preparing your chosen domain samples, measuring using one off-the-shelf performance (e.g., perplexity), and generating example continuations.\n",
    "\n",
    "2. **C-Level (30%)**– adapt the model using fine-tuning; compare results against the baseline created in pass task using both metrics and qualitative examples, and record training/inference times.\n",
    "\n",
    "3. **D-Level (10%)** – apply a parameter-efficient fine-tuning method (e.g., LoRA), and quantify the trade-off between trainable parameter count, training cost, and improvements in domain fidelity.\n",
    "\n",
    "For each task provide detailed analysis (max 2-3 pages for each task) on the steps you take for data processing, model training, text generation, justifications, and your observations. Please consider the D-level task needs detailed analysis and comparison between the methods you performed in P, C, and D tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P-Level Tasks (~60%)\n",
    "\n",
    "Goal: Evaluate Pretrained Model’s Generative Baseline\n",
    "\n",
    "1. Model & Domain Selection\n",
    "\n",
    "    . Choose a small, widely accessible GPT‑style model (e.g., GPT‑2 small or DistilGPT‑2).\n",
    "\n",
    "    . Pick a distinctive writing domain or author (e.g., Jane Austen’s novels, satirical news articles, scientific abstracts).\n",
    "\n",
    "2. Data Preparation\n",
    "\n",
    "    . Collect ~5–10 representative samples from your chosen domain.\n",
    "    \n",
    "    . Keep them short and manageable (e.g., one paragraph each).\n",
    "\n",
    "3. Baseline Generation\n",
    "\n",
    "    . Use a fixed prompt (e.g., “Continue this paragraph in the style of …”). You can use a prompt like this:\n",
    "        GEN_PROMPT = (\n",
    "            \"Continue the following passage in the same style:\\n\\n\"\n",
    "            \"The results indicate a statistically significant improvement over baseline models under limited compute budgets.\"\n",
    "        )\n",
    "\n",
    "    . Generate continuations using the pretrained model without any fine‑tuning. Briefly explore and discuss the steps you take for tokenization and giving prompt\n",
    "\n",
    "4. Evaluation\n",
    "\n",
    "    . Qualitatively assess style similarity. (write a short analysis on what you see on generated data, in comparison with actual data, in terms of grammar and similarity)\n",
    "\n",
    "    . Search for a evaluation metric and compute this simple metric for the generated data (e.g., perplexity on held‑out domain samples, or BLEU/ROUGE comparing to original domain variants)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pSCZIHouCLd-"
   },
   "source": [
    "\n",
    "## C-Level Tasks (~30%)\n",
    "\n",
    "Goal: Adaptation via Fine-Tuning \n",
    "\n",
    "1. Fine-tune the model (full-tuning) on your domain samples. Make choices (number of epochs, learning rate, context length, etc.) that fit within your computing environment.\n",
    "2. Generate same prompt continuation as the pass task.\n",
    "3. Re-evaluate the performance on sample generation. Compare style, fluency, and compare based on the evaluation metric you chose before.  \n",
    "4. Track the resources and report. Record the trainable parameters, training time, inference time.\n",
    "5. Introduce one modification of your own design (for example, a different hyperparameter setting, data sampling approach or model variant) and summarise its effect (performing the fine-tuning, sample generation, reevaluation and tracking the computational cost same as steps 1 to 4).\n",
    "5. Discuss the trade-off between computational cost and sample generation performance based on the mothods you performed in this task.\n",
    "Key points to cover:\n",
    "\n",
    "    - fine-tuning procedure and rationale  \n",
    "    - regenerated prompt comparison  \n",
    "    - computational resource comparison\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFcWSIbDCiQ9"
   },
   "source": [
    "## D-Level Tasks (~10%)\n",
    "\n",
    "Goal: Parameter-Efficient Fine-Tuning (PEFT)\n",
    "\n",
    "\n",
    "1. Apply a parameter-efficient adaptation method (for example LoRA or adapter modules) to your model. Discuss the justification behind choosing an specific form of PEFT. \n",
    "2. Apply chosen method using your domain data. Generate same prompt continuation. Re-evaluate performance on sample generation. Compare style, fluency, and compare based on the evaluation metric you chose before. \n",
    "3. Compare resource use (trainable parameter count, training time) and performance against the full fine-tuning methods mentioned on the C task.  \n",
    "4. Discuss the trade-off between computational cost and sample generation performance in comparison with previous methods in task C.\n",
    "Key points to cover:\n",
    "\n",
    "    - Parameter-Efficient Fine-Tuning procedure and rationale  \n",
    "    - regenerated prompt comparison  \n",
    "    - computational resource comparison\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mmxq_M0rO6PQ"
   },
   "source": [
    "## References:\n",
    "\n",
    "**GPT-2**  \n",
    "   Radford, A., Wu, J., Child, R., Luan, D., Amodei, D. & Sutskever, I. (2019). *Language Models are Unsupervised Multitask Learners*. OpenAI Technical Report.  \n",
    "   https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf\n",
    "\n",
    "\n",
    "**Adapter Layers**  \n",
    "   Houlsby, N., Giurgiu, A., Jastrzebski, S., Morrone, B., De Laroussilhe, Q., Gesmundo, A., Attariyan, M. & Gelly, S. (2019). *Parameter-Efficient Transfer Learning for NLP*. arXiv:1902.00751  \n",
    "   https://arxiv.org/abs/1902.00751\n",
    "\n",
    "**LoRA (Low-Rank Adaptation)**  \n",
    "   Hu, E. J., Tang, J., Rao, Y., Yu, Z., Fung, P. & Guo, J. (2021). *LoRA: Low-Rank Adaptation of Large Language Models*. arXiv:2106.09685  \n",
    "   https://arxiv.org/abs/2106.09685\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwTL8-WKDCFj"
   },
   "source": [
    "## Submission\n",
    "- Your notebook must run end-to-end without errors.  \n",
    "- Provide clear, concise commentary on your design choices and results.  \n",
    "- Combine code, figures and discussion in the report.\n",
    "\n",
    "Good luck and be creative!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMEWr6YjM901BJUZ03aTEzX",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
